{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38ca4dc-9f36-41c9-8187-6efbe7b98493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f012047-664d-4255-a45e-2cce6f1542bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_v3a_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3) , input_shape = (48,48,1), activation = 'relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3,3) , activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (3,3) , activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (3,3) , activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9fece90-b567-44c8-a97e-abb60ba6d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('CNN_v3a_200epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16686443-4a9e-4fbc-841c-22f7381df795",
   "metadata": {},
   "source": [
    "## Loading a test image and preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be578bf7-53e1-4c39-af14-71351cf2bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread('testimage_cropped.jpg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f8bb73e-ca2f-402a-9562-c9a0b7a1d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('display', test_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3dc92da-34da-46af-b33c-8ef6126aaadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_resized_gray = cv2.resize(test_image,(48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0335f7de-5745-4704-9abe-8e0c73ae32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('display', test_image_resized_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323caa45-450a-40c6-b6f0-5810541f0f98",
   "metadata": {},
   "source": [
    "## Prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce47e5f-70c9-4458-802d-6c65b0340385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(img):\n",
    "    img = cv2.resize(img, (48,48))\n",
    "    prediction = model.predict(img.reshape(1,48,48,1))\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    emotions = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
    "    \n",
    "    return emotions[int(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd96ed16-eb63-4bfe-b064-1828227e3265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angry'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emotion(test_image_resized_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59bedc99-8ecb-4300-84e4-a13742903009",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./test/happy/PrivateTest_13103594.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dfa48ff-cfa8-4b2c-afd1-123ac4da54f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c245d87-b136-48f6-b7ac-80f00169ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Test', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c6b77a9-20a8-4996-a21e-963acbf8b10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emotion(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a75715-add1-4170-99d2-5455f9e780a8",
   "metadata": {},
   "source": [
    "## Using HC to create a bounding box around face found in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f8e425f-1942-437a-92ae-872326758320",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_path = 'C:\\\\Users\\\\Randy\\\\Venv\\\\cv\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a653a981-fac4-41bb-8e68-4cb2f9f0384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = cv2.CascadeClassifier(hc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4390e9cb-f335-4efe-849e-be923dde2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = hc.detectMultiScale(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9b4649a-cf21-4126-b61c-e439d9573d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in faces:\n",
    "    x, y, w, h = face\n",
    "    cv2.rectangle(test_image,(x,y),(x+w, y+h),(0,0,255),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddc5d61a-6172-4636-a539-1dd63b324c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(img):\n",
    "    #hc_path = 'C:\\\\Users\\\\Randy\\\\Venv\\\\cv\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml'\n",
    "    #hc = cv2.CascadeClassifier(hc_path)\n",
    "    faces = hc.detectMultiScale(img)\n",
    "    for face in faces:\n",
    "        x, y, w, h = face\n",
    "        cv2.rectangle(img,(x,y),(x+w, y+h),(0,0,255),3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8d0765e-9be4-4cbf-9ad7-437485fe590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Faces Detected\", test_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "330b8d08-037c-4788-a643-4ce7d1838d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_path = 'C:\\\\Users\\\\Randy\\\\Venv\\\\cv\\\\Lib\\\\site-packages\\\\cv2\\\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ba81923-55fd-4e64-8e56-6ae8ac852491",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Faces Detected\", draw_bounding_box(test_image))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f783c580-8856-4e82-afb8-b2dff78870e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h = faces[0]\n",
    "cropped_face = test_image[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "426da9eb-1e39-482f-8458-e6f46e0ba70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_cropped_face(img):\n",
    "    faces = hc.detectMultiScale(img)\n",
    "    for (x,y,w,h) in faces:\n",
    "        img = img[y:y+h, x:x+w]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "257d2e1a-9982-4161-8c77-031eeb453e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Cropped Face\", cropped_face)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c122ca15-9373-47d2-94d5-1ae4202d5561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'surprise'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emotion(cropped_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99eee04e-8639-4ff3-9c57-2f8d00c43cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b44a0a4-af05-4a55-9d2e-3b81ec55a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not video_cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = hc.detectMultiScale(gray)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        face = gray[y:y+h, x:x+w]\n",
    "        \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, \n",
    "            predict_emotion(face), \n",
    "            (50, 50), #top left\n",
    "            font, 1, \n",
    "            (255, 0, 0), #BGR \n",
    "            2, \n",
    "            cv2.LINE_4)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', draw_bounding_box(frame))\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "video_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02367c1d-ddbd-4c1b-a106-a8a3e0c05251",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'C:\\\\Users\\\\Randy\\\\GitHub\\\\metamo\\\\uploaded_images\\\\20210815_140224.jpg'\n",
    "\n",
    "img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3225179c-8e56-4777-a993-43ee501fac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('example',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9038201c-0d83-4d02-9380-b5e68b614859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_cropped_face(img):\n",
    "    \"\"\"\n",
    "    Reads the img, detects a face in the image and returns a cropped image with only the face\n",
    "    :param img: img with a face\n",
    "    :return: the cropped version of only the face\n",
    "    \"\"\"\n",
    "    faces = hc.detectMultiScale(img)\n",
    "    for (x,y,w,h) in faces:\n",
    "        img = img[y:y+h, x:x+w]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aadc696b-0dbd-40e9-b86e-a1382801b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = return_cropped_face(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd63759f-58ac-478f-b3b4-2717e8a27990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 0), dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fa1f498-067d-4f35-ad82-32f14913f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Randy\\AppData\\Local\\Temp/ipykernel_12716/1512092736.py:1: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  assert img\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12716/1512092736.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884db421-e7e9-47a3-807d-086169daaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('example',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5051a-425d-4527-8c45-6d762e6cc564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
