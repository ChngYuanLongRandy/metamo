{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38ca4dc-9f36-41c9-8187-6efbe7b98493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b25fd84e-6e4a-4918-9fb9-301bd8f72c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e007537-0d20-49c8-864b-b0c27aebca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(512, (3,3), input_shape=(48,48,1),activation = 'relu'),\n",
    "    MaxPool2D(),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(512,(3,3), activation = 'relu'),\n",
    "    MaxPool2D(),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256,(3,3), activation = 'relu'),\n",
    "    MaxPool2D(),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256,(3,3), activation = 'relu'),\n",
    "    MaxPool2D(),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(512,activation = 'relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation = 'relu'),\n",
    "    Dense(7,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fece90-b567-44c8-a97e-abb60ba6d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('kdef_gray_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16686443-4a9e-4fbc-841c-22f7381df795",
   "metadata": {},
   "source": [
    "## Loading a test image and preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be578bf7-53e1-4c39-af14-71351cf2bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread('testimage_cropped.jpg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8bb73e-ca2f-402a-9562-c9a0b7a1d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('display', test_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3dc92da-34da-46af-b33c-8ef6126aaadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_resized_gray = cv2.resize(test_image,(48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0335f7de-5745-4704-9abe-8e0c73ae32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('display', test_image_resized_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323caa45-450a-40c6-b6f0-5810541f0f98",
   "metadata": {},
   "source": [
    "## Prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fce47e5f-70c9-4458-802d-6c65b0340385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(img):\n",
    "    img = cv2.resize(img, (48,48))\n",
    "    prediction = model.predict(img.reshape(1,48,48,1))\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    emotions = ['ANGRY','FEARFUL','DISGUSTED','HAPPY','SAD','SURPRISED','NEUTRAL']\n",
    "    \n",
    "    return emotions[int(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd96ed16-eb63-4bfe-b064-1828227e3265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DISGUSTED'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emotion(test_image_resized_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59bedc99-8ecb-4300-84e4-a13742903009",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./test/happy/PrivateTest_13103594.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dfa48ff-cfa8-4b2c-afd1-123ac4da54f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c245d87-b136-48f6-b7ac-80f00169ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Test', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c6b77a9-20a8-4996-a21e-963acbf8b10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DISGUSTED'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emotion(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a75715-add1-4170-99d2-5455f9e780a8",
   "metadata": {},
   "source": [
    "## Using HC to create a bounding box around face found in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8e425f-1942-437a-92ae-872326758320",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_path = '.\\haarcascade_frontalface_default.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a653a981-fac4-41bb-8e68-4cb2f9f0384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = cv2.CascadeClassifier(hc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4390e9cb-f335-4efe-849e-be923dde2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = hc.detectMultiScale(test_image,minNeighbors = 3,scaleFactor = 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74b7bed4-9005-4d99-86ce-37a8b22ed148",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_param = [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9b4649a-cf21-4126-b61c-e439d9573d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in faces:\n",
    "    x, y, w, h = face\n",
    "    cv2.rectangle(test_image,(x - adjust_param[0],y - adjust_param[1]),(x+w +adjust_param[0], y+h + adjust_param[1]),(0,0,255),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddc5d61a-6172-4636-a539-1dd63b324c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(img):\n",
    "    faces = hc.detectMultiScale(img)\n",
    "    for face in faces:\n",
    "        x, y, w, h = face\n",
    "        cv2.rectangle(img,(x - adjust_param[0],y - adjust_param[1]),(x+w +adjust_param[0], y+h + adjust_param[1]),(0,0,255),3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8d0765e-9be4-4cbf-9ad7-437485fe590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Faces Detected\", test_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ba81923-55fd-4e64-8e56-6ae8ac852491",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Faces Detected\", draw_bounding_box(test_image))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2cbc12c-3d73-49a5-841d-121de5f7c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_param = [50,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16c83d1e-4c0d-475a-8381-9c1216d964e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in faces:\n",
    "    x, y, w, h = face\n",
    "    cv2.rectangle(test_image,(x - adjust_param[0],y - adjust_param[1]),(x+w +adjust_param[0], y+h + adjust_param[1]),(0,0,255),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37bf8d26-8e41-4e01-bdc0-164566a1d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(img):\n",
    "    faces = hc.detectMultiScale(img)\n",
    "    for face in faces:\n",
    "        x, y, w, h = face\n",
    "        cv2.rectangle(img,(x - adjust_param[0],y - adjust_param[1]),(x+w +adjust_param[0], y+h + adjust_param[1]),(0,0,255),3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45b68bd3-16b6-4003-bfbe-d2867d010aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Faces Detected\", test_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "727f94a2-774c-428e-a8cb-97512182a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Faces Detected\", draw_bounding_box(test_image))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f783c580-8856-4e82-afb8-b2dff78870e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h = faces[0]\n",
    "cropped_face = test_image[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "426da9eb-1e39-482f-8458-e6f46e0ba70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_cropped_face(img):\n",
    "    faces = hc.detectMultiScale(img)\n",
    "    for (x,y,w,h) in faces:\n",
    "        img = img[y:y+h, x:x+w]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "257d2e1a-9982-4161-8c77-031eeb453e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Cropped Face\", cropped_face)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c122ca15-9373-47d2-94d5-1ae4202d5561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DISGUSTED'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emotion(cropped_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dcdf4d2-2983-41bf-8bea-2cfa6464a59a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mSTOP\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eee04e-8639-4ff3-9c57-2f8d00c43cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44a0a4-af05-4a55-9d2e-3b81ec55a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not video_cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = hc.detectMultiScale(gray)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        face = gray[y:y+h, x:x+w]\n",
    "        \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, \n",
    "            predict_emotion(face), \n",
    "            (50, 50), #top left\n",
    "            font, 1, \n",
    "            (255, 0, 0), #BGR \n",
    "            2, \n",
    "            cv2.LINE_4)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', draw_bounding_box(frame))\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "video_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
